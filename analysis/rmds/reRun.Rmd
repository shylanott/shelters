---
title: "reRun"
author: "Amber Thomas"
date: "9/19/2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Intro

After running the analysis in the `data_collection` and `analysis` Rmd files in this folder, I have discovered that I'm missing information for the state of Nevada. After conferring with folks at the PetFinder API team, I have confirmed that this is an API issue. In an effort to have a complete data set, I am going to re-run the analysis in a slightly different way.  Here's the plan:


* Hit V2 API to get all available adoptable dogs in each state (run Nevada separately using evenly spaced zipcodes)
* Come up with a list of all the shelter IDs and hit the V1 API for all full animal records for each shelter
* Combine the two datasets to add descriptions to all of the animal listings for IDs
* Run textual analysis
* Manually check data (accuracy of location, single location, who moved, whether animal has already been moved or will be upon adoption)

## Load Packages

```{r load_packages}
# For general data cleaning and analysis
library(tidyverse)
library(glue)
library(tibble)
library(googledrive)

# For keeping your files in relative directories
library(here)

# For dates
library(lubridate)

# For downloading data
library(jsonlite)
library(httr)
library(data.table)
library(xml2)

# For NLP
library(reticulate)
library(cleanNLP)
library(spacyr)
```

## Defining Functions

Before anything else, we need to set up the authorization for using both PetFinder API's

```{r setup_auth, eval = FALSE}
# access saved username and key
user <- Sys.getenv("PF_ID2")
pw <- Sys.getenv("PF_PW2")

# generate new token each session
tokenURL <- "https://api.petfinder.com/v2/oauth2/token"
auth <- POST(url = "https://api.petfinder.com/v2/oauth2/token",
                   body = list(grant_type = "client_credentials",
                               client_id = user, client_secret = pw),
                   encode = "json")

token <- content(auth)$access_token
```

Then, we'll need a few functions...

```{r v2_api}
# Pings API and accesses results
accessResults <- function(state, start_page = 1){
  base <- "https://api.petfinder.com/v2/animals?"
  req <- GET(url = paste0(base, "type=dog&status=adoptable&limit=100&location=", state, "&page=", start_page), add_headers(Authorization = paste("Bearer", token)))

 req
}
```

```{r}
dc <- accessResults("DC")
dcCon <- content(dc, "text")
```


```{r v2_clean}
# TODO Fix numbered extraction of API results

# Cleans results, converts to data frame and exports to file
cleanResults <- function(results, state){
  animals <- content(results)$animals

  # Flatten results to df
  pupAttr <- animals %>%
    {
      tibble(
        id = map_chr(., "id", .default = NA),
        org_id = map_chr(., "organization_id", .default = NA),
        url = map_chr(., "url", .default = NA),
        type = map_chr(., "type", .default = NA),
        species = map_chr(., "species", .default = NA),
        breed_primary = map_chr(., c("breeds", "primary"), .default = NA),
        breed_secondary = map_chr(., c("breeds", "secondary"), .default = NA),
        breed_mixed = map_lgl(., c("breeds", "mixed"), .default = NA),
        breed_unknown = map_chr(., c("breeds", "unknown"), .default = NA),
        color_primary = map_chr(., c("colors", "primary"), .default = NA),
        color_secondary = map_chr(., c("colors", "secondary"), .default = NA),
        color_tertiary = map_chr(., c("colors", "tertiary"), .default = NA),
        age = map_chr(., "age", .default = NA),
        sex = map_chr(., "gender", .default = NA),
        size = map_chr(., "size", .default = NA),
        coat = map_chr(., "coat", .default = NA),
        fixed = map_lgl(., c("attributes", "spayed_neutered"), .default = NA),
        house_trained = map_lgl(., c("attributes", "house_trained"), .default = NA),
        declawed = map_lgl(., c("attributes", "declawed"), .default = NA),
        special_needs = map_lgl(., c("attributes", "special_needs"), .default = NA),
        shots_current = map_lgl(., c("attributes", "shots_current"), .default = NA),
        env_children = map_lgl(., c("environment", "children"), .default = NA),
        env_dogs = map_lgl(., c("environment", "dogs"), .default = NA),
        env_cats = map_lgl(., c("environment", "cats"), .default = NA),
        name = map_chr(., "name", .default = NA),
        description = map_chr(., "description", .default = NA),
        tags = map(., "tags", .default = NA_character_),
        photo = map_chr(., c("photos", 1, "full"), .default = NA_character_),
        status = map_chr(., "status", .default = NA),
        posted = map_chr(., "published_at", .default = NA),
        contact_city = map_chr(., c("contact", "address", "city"), .default = NA),
        contact_state = map_chr(., c("contact", "address", "state"), .default = NA),
        contact_zip = map_chr(., c("contact", "address", "postcode"), .default = NA),
        contact_country = map_chr(., c("contact", "address", "country"), .default = NA)
      )
    }

  # tag list to vector
  pup_df <- pupAttr %>%
    rowwise() %>%
    mutate(tags = paste(unlist(tags), collapse = "|")) %>%
    mutate(stateQ = state,
           accessed = lubridate::today())

  # check if directory for today's data collection exists
  todayDir <- here::here("assets", "data", "raw_data", today())
  dogsDir <- here::here("assets", "data", "raw_data", today(), "dogs")
  sheltersDir <- here::here("assets", "data", "raw_data", today(), "shelters")

  # if directory doesn't exist, create it
  if (!dir.exists(todayDir)) dir.create(todayDir)
  if (!dir.exists(dogsDir)) dir.create(dogsDir)
  if (!dir.exists(sheltersDir)) dir.create(sheltersDir)

  # create new fileName
  fileName <- here::here("assets", "data", "raw_data", today(), "dogs", glue::glue("{state}_dogs.csv"))

  # Write to file
  write.table(pup_df, file = fileName, row.names = FALSE, append = TRUE, sep = ",", col.names = !file.exists(fileName))
}
```

```{r v2_pages}
# Function to loop through for remaining pages
findOtherPages <- function(state, start_page){
  req <- accessResults(state, start_page)
  cleanResults(req, state)
}
```

```{r v2_findDogs}
findDogs <- function(state, .pb = NULL){
  # adding progress bar
  if ((!is.null(.pb)) && inherits(.pb, "Progress") && (.pb$i < .pb$n)) .pb$tick()$print()

  # start accessing API
  req <- accessResults(state, start_page = 1)

  max_pages <- content(req)$pagination$total_pages

  cleanResults(req, state)

  # Loop through the remaining pages
  pages <- c(2:max_pages)
  argList <- list(state = state, pages = pages)
  args <- cross_df(argList)

  purrr::walk2(args$state, args$pages, findOtherPages)
}
```

```{r}
nvZip <- c("89009", "89011", "89014", '89015', '89019', '89024', '89027','89032', '89048', '89052', '89074', '89101','89103', '89104','89107','89113','89117','89118','89119','89120','89121','89122','89123','89128','89129','89130','89131','89134','89135','89136','89139','89143','89145','89146','89147','89148','89149','89183','89193','89406','89408','89410','89415','89423','89429','89431','89434','89436','89445','89447','89450','89451','89460','89502','89506','89511','89512','89523','89701','89702','89703','89704','89706','89801')
statesToCheck <- c(state.abb, nvZip, "DC")

start <- c("WA", "NY", "89801")
#purrr::walk(start, findDogs)

## Let's see how many states we get through
states <- statesToCheck[!statesToCheck %in% start]

limitedStates <- states[26:length(states)]

# Setting up progress bar
pb <- progress_estimated(length(limitedStates))

findSafely <- possibly(findDogs, otherwise = NA)

purrr::walk(limitedStates, findSafely, .pb = pb)

# Missing Washington DC and some NV zipcodes:
missing <- c("DC", '89118','89119','89120','89121','89122','89123','89128','89129','89130','89131','89134','89135','89136','89139','89143','89145','89146','89147','89148','89149','89183','89193','89406','89408','89410','89415','89423','89429','89431','89434','89436','89445','89447','89450','89451','89460','89502','89506','89511','89512','89523','89701','89702','89703','89704','89706','89801')
pb <- progress_estimated(length(missing))

purrr::walk(missing, findSafely, .pb = pb)
```




Now, all we need is to run `findDogs()` for each state. For Nevada, we will have a list of zipcodes instead, but the same structure should work just fine.

Next, we'll need to process the information within the response of `findDogs` to generate a list of all of the shelters that have dogs currently available for adoption. Use that list and the PetFinder API **V1**'s `shelter.getPets` to access all of the animals available at that shelter.

```{r create_single_file}
dogFiles <- list.files(path = here::here("assets", "data", "raw_data", today(), "dogs" ))
# read all files in and bind them together
dogs <- purrr::map_dfr(dogFiles, .f = function(file){

  location <- here::here("assets", "data", "raw_data", today(), "dogs", file)
  read_csv(location, col_names = TRUE,
           cols(
             .default = col_character(),
             breed_mixed = col_logical(),
             breed_unknown = col_logical(),
             fixed = col_logical(),
             house_trained = col_logical(),
             declawed = col_logical(),
             special_needs = col_logical(),
             shots_current = col_logical(),
             env_children = col_logical(),
             env_dogs = col_logical(),
             env_cats = col_logical()
           ))
}) %>%
  distinct(id, .keep_all = TRUE)

# write to file
write.csv(dogs, here::here("assets", "data", "raw_data", today(), "allDogs.csv"), row.names = FALSE)
```

```{r}
dogs <- read_csv(here::here("assets", "data", "raw_data", "2019-09-20", "allDogs.csv"))
```


```{r v1_api}
# Pings API and accesses results
accessShelters <- function(shelterID, start_page = 1){
  userV1 <- Sys.getenv("PF_V1")
  base <- "https://api.petfinder.com/shelter.getPets?"
  req <- GET(url = paste0(base, "key=", userV1,
        "&id=", shelterID, "&format=json&type=dog&status=A&count=1000&output=full&offset=", start_page))

 req
}
```


```{r v1_clean}
# Cleans results, converts to data frame and exports to file
cleanShelters <- function(results, shelterID){
  animals <- content(results)$petfinder$pet$pet

  # Flatten results to df
  pupAttr <- animals %>%
    {
      tibble(
        id = map_chr(., c("id", "$t"), .default = NA),
        org_id = map_chr(., c("shelterId", "$t"), .default = NA),
        type = map_chr(., c("animal", "$t"), .default = NA),
        description = map_chr(., c("description", "$t"), .default = NA),
      )
    }

  # tag list to vector
  pup_df <- pupAttr

  # create new fileName
  fileName <- here::here("assets", "data", "raw_data", today(), "shelters", glue::glue("{shelterID}_pets.csv"))

  # Write to file
  write.table(pup_df, file = fileName, row.names = FALSE, append = TRUE, sep = ",", col.names = !file.exists(fileName))
}
```


```{r}
lookupShelter <- function(shelterID, .pb = NULL){
  # adding progress bar
  if ((!is.null(.pb)) && inherits(.pb, "Progress") && (.pb$i < .pb$n)) .pb$tick()$print()
  Sys.sleep(0.001)

  req <- accessShelters(shelterID, start_page = 1)

  cleanShelters(req, shelterID)
}
```


```{r find_shelters}

findShelters <- function(date = today()){
  # start by loading all of the data back into R
  dogs <- read.csv(here::here("assets", "data", "raw_data", date, "allDogs.csv"), stringsAsFactors = FALSE, header = TRUE)

  # limit it down to just the unique shelter ids
  shelters <- dogs %>%
    count(org_id)

  sheltersList <- shelters$org_id

  pb = progress_estimated(length(sheltersList))

  purrr::walk(sheltersList, lookupShelter, .pb = pb)
}

```

Now to find those shelter details
```{r}
findShelters()
```
We'll combine the shelter details into a single file:

```{r message = FALSE, warning = FALSE}
shelterFiles <- list.files(path = here::here("assets", "data", "raw_data", today(), "shelters" ))
# read all files in and bind them together
shelterPets <- purrr::map_dfr(shelterFiles, .f = function(file){
  location <- here::here("assets", "data", "raw_data", today(), "shelters", file)
  read_csv(location, col_names = TRUE, col_types = "cccc")
})  %>% 
    filter(type == "Dog")


# write to file
write.csv(shelterPets, here::here("assets", "data", "raw_data", today(), "allShelters.csv"), row.names = FALSE)
```
```{r}
shelterPets <- read_csv(here::here("assets", "data", "raw_data", "2019-09-20", "allShelters.csv"))
```

```{r}
dogDescriptions <- dogs %>% 
  mutate(id = as.character(id)) %>% 
  select(-description) %>% 
  left_join(shelterPets, by = c("id", "org_id")) %>% 
  distinct(id, .keep_all = TRUE)

# write to file
write.csv(dogDescriptions, here::here("assets", "data", "raw_data", today(), "allDogDesc.csv"), row.names = FALSE)

```


Now to use some Regex to find animals `from` a place (but not where they've gone `to`) and also those that are `located in` a place

```{r}
regexLocs <- dogDescriptions %>% 
  mutate(from = str_extract_all(description, "from (.*?)[.?!]", simplify = FALSE),
         located = str_extract_all(description, "\\w*(?<!families|organization) located in (.*?)[.?!]", simplify = FALSE)) 


cleanRegex <- regexLocs %>% 
  gather("regex", "sentence", c("from", "located")) %>% 
  filter(!is.na(sentence)) %>% 
  unnest(sentence) %>% 
  mutate(onlySent = gsub("[:space:]to(.*?)[.?!]", "", sentence))

check <- tail(cleanRegex)
```

Now to setup `spacyR`

```{r}
use_condaenv("spacy_condaenv", required = TRUE)
cnlp_init_spacy()
```

And write a function to detect entities:

```{r}
labelEntities <- function(text, id){
  ent <- spacy_extract_entity(text, extended = TRUE) 
  
  if (!is.null(ent)){
    tags <- ent %>% 
      filter(ent_type == "GPE") %>%      
      mutate(id = id)

  
    fileName = here::here("assets", "data", "processed_data", today(), "from_locations.csv")
  
    # Write to file
    write.table(tags, file = fileName, row.names = FALSE, append = TRUE, sep = ",", col.names = !file.exists(fileName))
  }
}

fromLoc <- purrr::walk2(cleanRegex$onlySent, cleanRegex$id, labelEntities)
```

```{r}
fromLoc <- read_csv(here::here("assets", "data", "processed_data", today(), "from_locations.csv")) %>% 
  mutate(id = as.character(id)) %>% 
  left_join(dogDescriptions, by = c("id")) %>% 
  select(c("id", "contact_city", "contact_state", "description", "text")) %>% 
  rename("found" = "text")

write.csv(fromLoc, here::here("assets", "data", "processed_data", today(), "manual_locations.csv"), row.names = FALSE)
```


```{r}
# upload to google drive
folder <- as_dribble(as_id("1egKvQvptatpY6hveSrK3JbLj77FhaeGC"))
upload <- drive_upload(
  here::here("assets", "data", "processed_data", today(), "manual_locations.csv"),
  folder,
  name = "locations-sept",
  type = "spreadsheet"
)
```
And download again now that manual cleaning is done...

```{r}
googleLoc <- as_dribble(as_id("1yUwoh-qlEvRvkb8XPEUksku_VS0qbx-_nW_Ovw9Tb4o"))
drive_download(
  file = googleLoc,
  path = here::here("assets", "data", "processed_data", "2019-09-20", "cleaned_locations.csv"), 
  overwrite = TRUE
)
```

```{r}
manualLoc <- read_csv(here::here("assets", "data", "processed_data", "2019-09-20", "cleaned_locations.csv"))

cleanLoc <- manualLoc %>% 
  # remove any with TRUE in remove column
  filter(is.na(remove)) %>% 
  # convert shelter state to full state name for comparison
  mutate(shelterLoc = case_when(
    !is.na(state.name[match(contact_state, state.abb)]) ~ state.name[match(contact_state, state.abb)],
    contact_state == "DC" ~ "Washington DC",
    TRUE ~ contact_state
  )) %>% 
  mutate(origin = ifelse(is.na(manual), found, manual),
         match = origin == shelterLoc) %>% 
  filter(match == FALSE) %>% 
  distinct(id, origin, .keep_all = TRUE) %>% 
  select(-c(contact_city, contact_state, found, manual, remove, match))

originCount <- cleanLoc %>% 
  count(origin, sort = TRUE)
  

# are there any dogs with multiple origins?
multOrigins <- cleanLoc %>% 
  count(id, sort = TRUE) %>% 
  filter(n > 1)

# nope! All good :) 
```

## Prepare Data for Viz

Now that the data is all cleaned, I just need to prepare it for the viz.

First, let's output all of the data for the dogs that we know have been moved.

```{r}
# start by narrowing our data down to dogs that have moved
descDogs <- cleanLoc %>% 
  left_join(dogs, by = "id") %>% 
  select(-description.y) %>% 
  rename(description = description.x)
```

```{r}
`%notin%` <- purrr::negate(`%in%`)

# import breed to dog icon crosswalk
googleLoc <- as_id("https://docs.google.com/spreadsheets/d/18h1C-ey0cVElZotdYZ3aEtRokc7LXUDVkl1DlmnRQc4/edit#gid=1648478200")
drive_download(
  file = googleLoc,
  path = here::here("assets", "data", "processed_data", "cleaned_breeds.csv"), 
  overwrite = TRUE
)


manualBreeds <- read_csv(here::here("assets", "data", "processed_data", "cleaned_breeds.csv")) %>% 
  select(-n)
```


```{r}
# now just the info we need for the viz
exportedDogs <- descDogs %>% 
  select(c(id, breed_primary, breed_secondary, age, sex, name, size, origin, shelterLoc)) %>% 
  rename("original_state" = "origin", "final_state" = "shelterLoc") %>% 
  left_join(manualBreeds)

# export to proper folder for js
puddingR::export_data(exportedDogs, "exportedDogs", directory = "../../src/assets/data/")
```



Alright, now to get state by state info:

```{r}
most_exported <- descDogs %>% 
  count(origin, sort = TRUE) %>% 
  rename(location = origin) %>% 
  rename(exported = n)

most_imported <- descDogs %>% 
  count(shelterLoc, sort = TRUE) %>% 
  rename(imported = n, location = shelterLoc)

totalAvailable <- dogs %>% 
  mutate(shelterLoc = case_when(
    !is.na(state.name[match(contact_state, state.abb)]) ~ state.name[match(contact_state, state.abb)],
    contact_state == "DC" ~ "Washington DC",
    TRUE ~ contact_state
  )) %>% 
  count(shelterLoc, sort = TRUE) %>% 
  mutate(remove = case_when(
    grepl("[[:digit:]]", shelterLoc) ~ TRUE,
    shelterLoc == "NB" | shelterLoc == "QC" ~ TRUE, 
    TRUE ~ FALSE
  )) %>% 
  filter(remove == FALSE) %>% 
  select(-remove)

allMoves <- most_exported %>% 
  full_join(most_imported, by = "location") %>% 
  full_join(totalAvailable, by = c("location" = "shelterLoc")) %>% 
  rename(total = n) %>%   
  mutate(inUS = case_when(
    location %in% state.name ~ TRUE,
    location == "Washington DC" ~ TRUE,
    #location == "Puerto Rico" ~ TRUE, 
    TRUE ~ FALSE
  )) %>% 
  mutate(inUS = tolower(inUS))

puddingR::export_data(allMoves, "importExport", directory = "../../src/assets/data/")
```


```{r}
percentOutUS <- allMoves %>% 
  ungroup() %>% 
  group_by(inUS) %>% 
  summarise(total = n())
```

How many didn't export or import?
```{r}
onlyLocal <- allMoves %>% 
  filter(is.na(imported) & is.na(exported))

check <- dogs %>% 
  filter(contact_state == "WY")

stillThere <- descDogs %>% 
  count(still_there)
```

## Hurricanes

Out of curiosity, how many of these dogs were moved due to hurricanes? 

```{r}
hurricanes <- descDogs %>% 
  mutate(hurricaneMention = str_extract_all(description, "hurricane|Hurricane|hurricanes|Hurricanes (.*?)[.?!]", simplify = FALSE)) %>% 
  filter(hurricaneMention != "character(0)")
```



